{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Entity_Extraction_keras_modification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxO5K86qtwbb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NZxp-tBaPmw"
      },
      "source": [
        "The following modification is an attempt to move all text preocessing into layers which can be included with the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmrNPFQNTWcu"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AOJvFI_TWKi",
        "outputId": "0000c05f-56c0-44dd-c064-3285a7524665"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydmpjBUaTSox"
      },
      "source": [
        "# Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLGnjMKjTQfO",
        "outputId": "22729891-8b19-4ac7-a19b-b0ba23112f53"
      },
      "source": [
        "#import packages\r\n",
        "import pandas as pd\r\n",
        "import io\r\n",
        "import os\r\n",
        "from google.colab import files\r\n",
        "import numpy as np\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "nltk.download('stopwords')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.models import Model, Input, Sequential\r\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\r\n",
        "\r\n",
        "\r\n",
        "random_state = 5590"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB09vLl4nS3u"
      },
      "source": [
        "# Import Data\r\n",
        "The training data is imported and the necessary columns are converted to lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T12Fmn31TQDB"
      },
      "source": [
        "#import data\r\n",
        "path_dir_data = 'gdrive/MyDrive/Colab/CausalityExtractionNLP/data'\r\n",
        "file_training_data = 'training_data.xlsx'\r\n",
        "path_training_data = os.path.join(path_dir_data, file_training_data)\r\n",
        "dataset = pd.read_excel(path_training_data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiQtrZHcajz1"
      },
      "source": [
        "# -*- coding: utf-8 -*-\r\n",
        "\"\"\"Entity_Extraction.ipynb\r\n",
        "\r\n",
        "Automatically generated by Colaboratory.\r\n",
        "\r\n",
        "Original file is located at\r\n",
        "    https://colab.research.google.com/drive/1MEpAYceQU4SAev6RSyfL5DJxQnk2ClZp\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "#convert into lists\r\n",
        "df = pd.DataFrame({'label':dataset.causal_relationship, \r\n",
        "                   'text':dataset.sentence, \r\n",
        "                   'node1':dataset.node_1, \r\n",
        "                   'node2':dataset.node_2})\r\n",
        "df = df.dropna()\r\n",
        "description_list = df['text'].tolist()\r\n",
        "node1_list = df['node1'].tolist()\r\n",
        "node2_list = df['node2'].tolist()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64dw6NIFtUq_"
      },
      "source": [
        "# Split Data into Training / Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ajaFUJBtVFh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "df_train, df_test = train_test_split(df,\r\n",
        "                                     test_size=0.25, \r\n",
        "                                     random_state = random_state)\r\n",
        "\r\n",
        "text_train = df_train['text'].tolist()\r\n",
        "text_test = df_test['text'].tolist()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4d2K_IRt-Vd"
      },
      "source": [
        "# Extract Training Text and Create Vectorization Layer\r\n",
        "\r\n",
        "We perform this step here just to ensure we know the size of our vocabulary. We will need to length to define our target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_eOgL-Dt-BD",
        "outputId": "1d01bf8f-5189-46c1-b6bc-5d455d28dee8"
      },
      "source": [
        "from keras.layers.experimental.preprocessing import TextVectorization\r\n",
        "max_features = 1000\r\n",
        "max_len = 70\r\n",
        "\r\n",
        "vectorize_layer = TextVectorization(\r\n",
        "    max_tokens=max_features,\r\n",
        "    output_mode='int',\r\n",
        "    output_sequence_length=max_len)\r\n",
        "\r\n",
        "vectorize_layer.adapt(text_train)\r\n",
        "\r\n",
        "vocab_len = len(vectorize_layer.get_vocabulary())\r\n",
        "\r\n",
        "print(vocab_len)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhIxD_XF_aXn"
      },
      "source": [
        "model_text = Sequential()\r\n",
        "model_text.add(tf.keras.Input(shape=(1,), dtype=tf.string))\r\n",
        "model_text.add(vectorize_layer)\r\n",
        "x_train_xfrm = model_text.predict(text_train)\r\n",
        "x_test_xfrm = model_text.predict(text_test)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ber3b53hqSzf"
      },
      "source": [
        "# Create Targte Variable\r\n",
        "We need to define a target variable.\r\n",
        "\r\n",
        "This is a several step process, and we need to do this for train and test sets, so it is best to create a function.\r\n",
        "## Input Values / Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LECLRBAV3Zhm"
      },
      "source": [
        "def sentenceGetter(sentence, labels):\r\n",
        "   vocab = sentence.split(\" \")\r\n",
        "   sen_group =[]\r\n",
        "   for i in range(len(vocab)):\r\n",
        "     sen_group.append((vocab[i], labels[i]))\r\n",
        "   return sen_group\r\n",
        "\r\n",
        "#create tags\r\n",
        "tags = []\r\n",
        "tags.append(0)\r\n",
        "tags.append(1)\r\n",
        "tags.append(2)\r\n",
        "n_tags = len(tags)\r\n",
        "\r\n",
        "\r\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VFPip9o3d5y"
      },
      "source": [
        "## Target Variable Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0-Asyi93de_"
      },
      "source": [
        "def create_target(df):\r\n",
        "    description_list = df['text'].tolist()\r\n",
        "    node1_list = df['node1'].tolist()\r\n",
        "    node2_list = df['node2'].tolist()\r\n",
        "\r\n",
        "    # Text Processing\r\n",
        "    for i, n in enumerate(node2_list): \r\n",
        "        node2_list[i] = n.lower() \\\r\n",
        "                        .replace('.', '') \\\r\n",
        "                        .replace(',', '')\r\n",
        "\r\n",
        "    for j, n in enumerate(node1_list): \r\n",
        "        node1_list[j] = n.lower() \\\r\n",
        "                        .replace('.', '') \\\r\n",
        "                        .replace(',', '')\r\n",
        "\r\n",
        "    for k, n in enumerate(description_list): \r\n",
        "        description_list[k] = n.lower() \\\r\n",
        "                                .replace('.', '') \\\r\n",
        "                                .replace(',', '') \\\r\n",
        "                                .replace(':', '')\r\n",
        "    \r\n",
        "    # Generate Labels\r\n",
        "    labels = []\r\n",
        "    for i, sen in enumerate(description_list):\r\n",
        "        words = sen.split(\" \")\r\n",
        "        labels1 = np.zeros(len(words))\r\n",
        "        node1 = node1_list[i].split(\" \")\r\n",
        "        node2 = node2_list[i].split(\" \")\r\n",
        "\r\n",
        "        for n1 in node1: \r\n",
        "            hold = words.index(n1)\r\n",
        "            labels1[hold] = 1\r\n",
        "\r\n",
        "        for n2 in node2: \r\n",
        "            hold = words.index(n2)\r\n",
        "            labels1[hold] = 2\r\n",
        "\r\n",
        "        labels.append(labels1)\r\n",
        "\r\n",
        "    # Append Sentences\r\n",
        "    sentences = []\r\n",
        "\r\n",
        "    for i, sentence in enumerate(description_list): \r\n",
        "        sen_group = sentenceGetter(sentence, labels[i])\r\n",
        "        sentences.append(sen_group)\r\n",
        "\r\n",
        "    # Keras Processing\r\n",
        "    #process data\r\n",
        "    y = [[tag2idx[w[1]] for w in s] for s in sentences]\r\n",
        "\r\n",
        "    y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[0])\r\n",
        "\r\n",
        "    y = [to_categorical(i, num_classes=n_tags) for i in y]\r\n",
        "\r\n",
        "    return(y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "526v_vNB4cH_"
      },
      "source": [
        "### Execute Variable Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY5f6yxt4Nz2"
      },
      "source": [
        "y_train = create_target(df_train)\r\n",
        "y_te = create_target(df_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ5e2aBG4uuU"
      },
      "source": [
        "## Convert Y Test\r\n",
        "This step essentially reverses the one-hot encoding of the target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJfNTAdwXTfk"
      },
      "source": [
        "y_test = []\r\n",
        "for y in y_te:\r\n",
        "  y_hold = []\r\n",
        "  for r in y:\r\n",
        "    if r[0] == 1:\r\n",
        "      y_hold.append(0)\r\n",
        "    if r[1] ==1:\r\n",
        "      y_hold.append(1)\r\n",
        "    if r[2] == 1:\r\n",
        "      y_hold.append(2)\r\n",
        "  y_test.append(y_hold)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OansVCCY4-gr"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWeBnhPNIA5M"
      },
      "source": [
        "## Text Process External"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "g5AauhQSH7wu",
        "outputId": "e866fb0c-1486-4816-9751-f2b11aa168ef"
      },
      "source": [
        "embedding_dim = 64\r\n",
        "\r\n",
        "x_train_xfrm = model_text.predict(text_train)\r\n",
        "y_train_np = np.array(y_train_np)\r\n",
        "\r\n",
        "#build LSTM\r\n",
        "model = Sequential()\r\n",
        "model.add(tf.keras.Input(shape=(max_len,)))\r\n",
        "model.add(Embedding(input_dim = max_features + 1, \r\n",
        "                    output_dim = embedding_dim,\r\n",
        "                    input_length = max_len))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "model.add(Bidirectional(LSTM(units=3, return_sequences=True, \r\n",
        "                             recurrent_dropout=0.1)))\r\n",
        "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\"))) \r\n",
        "\r\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\r\n",
        "              metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# history = model.fit(x_train_xfrm, y_train_np, batch_size=32, epochs=60, \r\n",
        "#                     validation_split=0.1, verbose=1)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_18 (Embedding)     (None, 70, 64)            64064     \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 70, 64)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_18 (Bidirectio (None, 70, 6)             1632      \n",
            "_________________________________________________________________\n",
            "time_distributed_18 (TimeDis (None, 70, 3)             21        \n",
            "=================================================================\n",
            "Total params: 65,717\n",
            "Trainable params: 65,717\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "14/14 [==============================] - 7s 130ms/step - loss: 0.9924 - accuracy: 0.8824 - val_loss: 0.8295 - val_accuracy: 0.9051\n",
            "Epoch 2/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.7855 - accuracy: 0.8959 - val_loss: 0.6407 - val_accuracy: 0.9051\n",
            "Epoch 3/60\n",
            "14/14 [==============================] - 1s 83ms/step - loss: 0.6101 - accuracy: 0.8924 - val_loss: 0.4986 - val_accuracy: 0.9051\n",
            "Epoch 4/60\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.4803 - accuracy: 0.8947 - val_loss: 0.4132 - val_accuracy: 0.9054\n",
            "Epoch 5/60\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.4054 - accuracy: 0.8970 - val_loss: 0.3587 - val_accuracy: 0.9065\n",
            "Epoch 6/60\n",
            " 1/14 [=>............................] - ETA: 1s - loss: 0.3841 - accuracy: 0.8813"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-23505af7fd20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_xfrm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i0HPhyQH8yu"
      },
      "source": [
        "## Text Processing Embedded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4ihkry6Mh_M"
      },
      "source": [
        "text_train_tf = tf.data.Dataset.from_tensor_slices(text_train)\r\n",
        "text_train_np = np.array(text_train)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCPJGv_J-WpL",
        "outputId": "4080a5fc-f80d-4f60-acb7-49280bba770e"
      },
      "source": [
        "embedding_dim = 64\r\n",
        "\r\n",
        "#build LSTM\r\n",
        "model = Sequential()\r\n",
        "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\r\n",
        "model.add(vectorize_layer)\r\n",
        "model.add(Embedding(input_dim = max_features + 1, \r\n",
        "                    output_dim = embedding_dim,\r\n",
        "                    input_length = max_len))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "model.add(Bidirectional(LSTM(units=3, return_sequences=True, recurrent_dropout=0.1)))\r\n",
        "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\"))) # softmax output layer\r\n",
        "\r\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n",
        "history = model.fit(text_train_np, y_train_np, batch_size=32, epochs=60, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization (TextVect (None, 70)                0         \n",
            "_________________________________________________________________\n",
            "embedding_24 (Embedding)     (None, 70, 64)            64064     \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 70, 64)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_24 (Bidirectio (None, 70, 6)             1632      \n",
            "_________________________________________________________________\n",
            "time_distributed_24 (TimeDis (None, 70, 3)             21        \n",
            "=================================================================\n",
            "Total params: 65,717\n",
            "Trainable params: 65,717\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "14/14 [==============================] - 7s 140ms/step - loss: 1.0415 - accuracy: 0.6299 - val_loss: 0.8642 - val_accuracy: 0.9054\n",
            "Epoch 2/60\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.8162 - accuracy: 0.8906 - val_loss: 0.6554 - val_accuracy: 0.9051\n",
            "Epoch 3/60\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.6201 - accuracy: 0.8926 - val_loss: 0.4928 - val_accuracy: 0.9051\n",
            "Epoch 4/60\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.4748 - accuracy: 0.8940 - val_loss: 0.3876 - val_accuracy: 0.9051\n",
            "Epoch 5/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.3824 - accuracy: 0.8923 - val_loss: 0.3250 - val_accuracy: 0.9057\n",
            "Epoch 6/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.3246 - accuracy: 0.8956 - val_loss: 0.2856 - val_accuracy: 0.9074\n",
            "Epoch 7/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.2903 - accuracy: 0.8963 - val_loss: 0.2581 - val_accuracy: 0.9083\n",
            "Epoch 8/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.2608 - accuracy: 0.9023 - val_loss: 0.2360 - val_accuracy: 0.9137\n",
            "Epoch 9/60\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.2420 - accuracy: 0.9063 - val_loss: 0.2178 - val_accuracy: 0.9152\n",
            "Epoch 10/60\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.2167 - accuracy: 0.9139 - val_loss: 0.2028 - val_accuracy: 0.9190\n",
            "Epoch 11/60\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.2062 - accuracy: 0.9206 - val_loss: 0.1901 - val_accuracy: 0.9250\n",
            "Epoch 12/60\n",
            "14/14 [==============================] - 1s 106ms/step - loss: 0.1897 - accuracy: 0.9268 - val_loss: 0.1804 - val_accuracy: 0.9256\n",
            "Epoch 13/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1806 - accuracy: 0.9314 - val_loss: 0.1705 - val_accuracy: 0.9324\n",
            "Epoch 14/60\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.1775 - accuracy: 0.9341 - val_loss: 0.1642 - val_accuracy: 0.9324\n",
            "Epoch 15/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.1634 - accuracy: 0.9411 - val_loss: 0.1563 - val_accuracy: 0.9396\n",
            "Epoch 16/60\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.1558 - accuracy: 0.9465 - val_loss: 0.1500 - val_accuracy: 0.9414\n",
            "Epoch 17/60\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.1493 - accuracy: 0.9480 - val_loss: 0.1466 - val_accuracy: 0.9432\n",
            "Epoch 18/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1485 - accuracy: 0.9491 - val_loss: 0.1401 - val_accuracy: 0.9494\n",
            "Epoch 19/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1382 - accuracy: 0.9523 - val_loss: 0.1362 - val_accuracy: 0.9527\n",
            "Epoch 20/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1301 - accuracy: 0.9561 - val_loss: 0.1307 - val_accuracy: 0.9571\n",
            "Epoch 21/60\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.1291 - accuracy: 0.9581 - val_loss: 0.1289 - val_accuracy: 0.9568\n",
            "Epoch 22/60\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.1283 - accuracy: 0.9569 - val_loss: 0.1260 - val_accuracy: 0.9583\n",
            "Epoch 23/60\n",
            "14/14 [==============================] - 1s 92ms/step - loss: 0.1189 - accuracy: 0.9618 - val_loss: 0.1234 - val_accuracy: 0.9589\n",
            "Epoch 24/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1206 - accuracy: 0.9617 - val_loss: 0.1207 - val_accuracy: 0.9601\n",
            "Epoch 25/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1150 - accuracy: 0.9622 - val_loss: 0.1193 - val_accuracy: 0.9589\n",
            "Epoch 26/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1105 - accuracy: 0.9631 - val_loss: 0.1167 - val_accuracy: 0.9619\n",
            "Epoch 27/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1041 - accuracy: 0.9655 - val_loss: 0.1149 - val_accuracy: 0.9628\n",
            "Epoch 28/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1044 - accuracy: 0.9653 - val_loss: 0.1142 - val_accuracy: 0.9625\n",
            "Epoch 29/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.1037 - accuracy: 0.9657 - val_loss: 0.1136 - val_accuracy: 0.9616\n",
            "Epoch 30/60\n",
            "14/14 [==============================] - 1s 92ms/step - loss: 0.1086 - accuracy: 0.9633 - val_loss: 0.1135 - val_accuracy: 0.9616\n",
            "Epoch 31/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.0977 - accuracy: 0.9682 - val_loss: 0.1126 - val_accuracy: 0.9628\n",
            "Epoch 32/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.0972 - accuracy: 0.9671 - val_loss: 0.1124 - val_accuracy: 0.9625\n",
            "Epoch 33/60\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.0966 - accuracy: 0.9681 - val_loss: 0.1111 - val_accuracy: 0.9631\n",
            "Epoch 34/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.0962 - accuracy: 0.9673 - val_loss: 0.1130 - val_accuracy: 0.9613\n",
            "Epoch 35/60\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.0937 - accuracy: 0.9672 - val_loss: 0.1126 - val_accuracy: 0.9607\n",
            "Epoch 36/60\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.0929 - accuracy: 0.9682 - val_loss: 0.1101 - val_accuracy: 0.9625\n",
            "Epoch 37/60\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.0903 - accuracy: 0.9681 - val_loss: 0.1103 - val_accuracy: 0.9622\n",
            "Epoch 38/60\n",
            "14/14 [==============================] - 1s 92ms/step - loss: 0.0942 - accuracy: 0.9674 - val_loss: 0.1099 - val_accuracy: 0.9628\n",
            "Epoch 39/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.0966 - accuracy: 0.9660 - val_loss: 0.1104 - val_accuracy: 0.9631\n",
            "Epoch 40/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.0873 - accuracy: 0.9687 - val_loss: 0.1101 - val_accuracy: 0.9622\n",
            "Epoch 41/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.0808 - accuracy: 0.9723 - val_loss: 0.1092 - val_accuracy: 0.9619\n",
            "Epoch 42/60\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.0836 - accuracy: 0.9716 - val_loss: 0.1096 - val_accuracy: 0.9631\n",
            "Epoch 43/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.0838 - accuracy: 0.9702 - val_loss: 0.1099 - val_accuracy: 0.9628\n",
            "Epoch 44/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.0811 - accuracy: 0.9717 - val_loss: 0.1098 - val_accuracy: 0.9622\n",
            "Epoch 45/60\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.0778 - accuracy: 0.9721 - val_loss: 0.1114 - val_accuracy: 0.9610\n",
            "Epoch 46/60\n",
            "14/14 [==============================] - 1s 91ms/step - loss: 0.0776 - accuracy: 0.9732 - val_loss: 0.1136 - val_accuracy: 0.9598\n",
            "Epoch 47/60\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 0.0804 - accuracy: 0.9712 - val_loss: 0.1119 - val_accuracy: 0.9613\n",
            "Epoch 48/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.0796 - accuracy: 0.9719 - val_loss: 0.1120 - val_accuracy: 0.9616\n",
            "Epoch 49/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.0743 - accuracy: 0.9741 - val_loss: 0.1124 - val_accuracy: 0.9619\n",
            "Epoch 50/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.0739 - accuracy: 0.9742 - val_loss: 0.1114 - val_accuracy: 0.9625\n",
            "Epoch 51/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.0763 - accuracy: 0.9731 - val_loss: 0.1113 - val_accuracy: 0.9607\n",
            "Epoch 52/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.0739 - accuracy: 0.9739 - val_loss: 0.1122 - val_accuracy: 0.9604\n",
            "Epoch 53/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.0773 - accuracy: 0.9718 - val_loss: 0.1131 - val_accuracy: 0.9607\n",
            "Epoch 54/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.0704 - accuracy: 0.9755 - val_loss: 0.1148 - val_accuracy: 0.9601\n",
            "Epoch 55/60\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.0713 - accuracy: 0.9754 - val_loss: 0.1118 - val_accuracy: 0.9610\n",
            "Epoch 56/60\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.0728 - accuracy: 0.9747 - val_loss: 0.1140 - val_accuracy: 0.9616\n",
            "Epoch 57/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.0730 - accuracy: 0.9733 - val_loss: 0.1140 - val_accuracy: 0.9619\n",
            "Epoch 58/60\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.0702 - accuracy: 0.9747 - val_loss: 0.1138 - val_accuracy: 0.9610\n",
            "Epoch 59/60\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.0701 - accuracy: 0.9750 - val_loss: 0.1155 - val_accuracy: 0.9613\n",
            "Epoch 60/60\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 0.0714 - accuracy: 0.9756 - val_loss: 0.1156 - val_accuracy: 0.9598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbwWymv2XLGR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "d6932542-fd39-4378-b4eb-8659a5af1013"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\r\n",
        "\r\n",
        "#plot training and validation accuracy\r\n",
        "f = plt.figure(figsize=(5,5))\r\n",
        "plt.plot(hist[\"accuracy\"], label =' Training Accuracy')\r\n",
        "plt.plot(hist[\"val_accuracy\"], label='Validation Accuracy')\r\n",
        "plt.legend(loc=\"upper left\")\r\n",
        "plt.show()\r\n",
        "f.savefig( \"test.png\")\r\n",
        "# f.download(\"test.png\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwE-elwlW-rf",
        "outputId": "b1477b3c-ad7a-4eab-dca6-b03a171f9320"
      },
      "source": [
        "#calculate test set accuracy\r\n",
        "error = []\r\n",
        "false0 = []\r\n",
        "num1 = []\r\n",
        "num2 = []\r\n",
        "false1 = []\r\n",
        "for i in range(len(x_test_xfrm)):\r\n",
        "  p = model.predict(np.array([x_test_xfrm[i]]))\r\n",
        "  p = np.argmax(p, axis=-1)\r\n",
        "  ypred = p[0]\r\n",
        "  yt = y_test[i]\r\n",
        "  for j in range(len(ypred)):\r\n",
        "    if yt[j] == 1:\r\n",
        "      num1.append(1)\r\n",
        "    if yt[j] == 2:\r\n",
        "      num2.append(1)\r\n",
        "    if ypred[j] == yt[j]:\r\n",
        "      error.append(0)\r\n",
        "    else:\r\n",
        "      error.append(1)\r\n",
        "      if yt[j] == 1:\r\n",
        "        false0.append(True)\r\n",
        "      else:\r\n",
        "        false0.append(False)\r\n",
        "      if yt[j] == 2:\r\n",
        "        false1.append(True)\r\n",
        "      else:\r\n",
        "        false1.append(False)\r\n",
        "\r\n",
        "#overall accuracy\r\n",
        "print(1 - sum(error)/len(error))\r\n",
        "\r\n",
        "#accuracy of node1 classification\r\n",
        "print(1 - sum(false0)/sum(num1))\r\n",
        "\r\n",
        "#accuracy of node2 classification\r\n",
        "print(1 - sum(false1)/sum(num2))\r\n",
        "\r\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.958041329739443\n",
            "0.8131313131313131\n",
            "0.7150537634408602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOoxfczhTLwT"
      },
      "source": [
        "# Save and Restore Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW25ooyxTLwU"
      },
      "source": [
        "## Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9tFduNNTLwU",
        "outputId": "c75d869b-986b-440b-8d18-bf690ea613c4"
      },
      "source": [
        "# Export Model\n",
        "folder_keras_model = 'entity_extraction_w_processing_keras'\n",
        "path_keras_model = os.path.join(path_dir_data, folder_keras_model)\n",
        "\n",
        "model.save(path_keras_model)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: gdrive/MyDrive/Colab/CausalityExtractionNLP/data/entity_extraction_w_processing_keras/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X5xtWPdTLwV"
      },
      "source": [
        "# Restore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lApnHIrTLwW"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "model = keras.models.load_model(path_keras_model)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDuFymAtVzvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83088c6-5280-476a-b532-ed2bbbe7aedc"
      },
      "source": [
        "vec = model.get_layer('text_vectorization')\r\n",
        "vec.get_vocabulary()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'hypo',\n",
              " 'the',\n",
              " 'and',\n",
              " 'performance',\n",
              " 'of',\n",
              " 'to',\n",
              " 'a',\n",
              " 'positively',\n",
              " 'is',\n",
              " 'related',\n",
              " '1',\n",
              " 'with',\n",
              " 'will',\n",
              " '2',\n",
              " 'that',\n",
              " 'on',\n",
              " 'be',\n",
              " 'between',\n",
              " 'in',\n",
              " 'positive',\n",
              " 'relationship',\n",
              " '3',\n",
              " 'associated',\n",
              " 'environmental',\n",
              " '4',\n",
              " 'reputation',\n",
              " 'higher',\n",
              " 'firms',\n",
              " 'market',\n",
              " 'are',\n",
              " 'organizational',\n",
              " 'firm',\n",
              " 'turnover',\n",
              " 'management',\n",
              " 'strategy',\n",
              " 'employee',\n",
              " 'practices',\n",
              " 'effect',\n",
              " 'more',\n",
              " 'have',\n",
              " 'greater',\n",
              " 'csr',\n",
              " 'than',\n",
              " 'impact',\n",
              " '5',\n",
              " 'for',\n",
              " 'financial',\n",
              " 'its',\n",
              " 'systems',\n",
              " 'level',\n",
              " 'negatively',\n",
              " 'customer',\n",
              " 'satisfaction',\n",
              " 'orientation',\n",
              " 'rm',\n",
              " 'not',\n",
              " 'high',\n",
              " 'has',\n",
              " 'by',\n",
              " 'rms',\n",
              " 'as',\n",
              " 'innovation',\n",
              " 'human',\n",
              " 'hrm',\n",
              " 'an',\n",
              " '6',\n",
              " 'there',\n",
              " 'competitive',\n",
              " 'quality',\n",
              " 'nancial',\n",
              " 'their',\n",
              " 'resource',\n",
              " 'negative',\n",
              " 'hr',\n",
              " 'product',\n",
              " 'levels',\n",
              " 'interaction',\n",
              " 'business',\n",
              " 'job',\n",
              " 'hypothesis',\n",
              " 'better',\n",
              " 'was',\n",
              " 'pay',\n",
              " 'likely',\n",
              " 'firms',\n",
              " 'work',\n",
              " 'support',\n",
              " 'signicantly',\n",
              " 'economic',\n",
              " 'corporate',\n",
              " 'commitment',\n",
              " 'we',\n",
              " 'social',\n",
              " 'results',\n",
              " 'information',\n",
              " 'productivity',\n",
              " 'lower',\n",
              " 'integration',\n",
              " 'control',\n",
              " 'rms',\n",
              " 'use',\n",
              " 'such',\n",
              " 'outcomes',\n",
              " 'it',\n",
              " 'flexibility',\n",
              " 'both',\n",
              " 'when',\n",
              " 'time',\n",
              " 'rates',\n",
              " 'perceived',\n",
              " 'organizations',\n",
              " 'or',\n",
              " 'manufacturing',\n",
              " 'iso',\n",
              " 'involvement',\n",
              " 'employment',\n",
              " 'culture',\n",
              " 'configuration',\n",
              " 'capital',\n",
              " 'at',\n",
              " '8',\n",
              " 'which',\n",
              " 'team',\n",
              " 'subsidiaries',\n",
              " 'proactive',\n",
              " 'new',\n",
              " 'leadership',\n",
              " 'inuence',\n",
              " 'growth',\n",
              " 'experience',\n",
              " 'enhance',\n",
              " 'compensation',\n",
              " 'collaboration',\n",
              " '7',\n",
              " '14001',\n",
              " 'would',\n",
              " 'tc',\n",
              " 'success',\n",
              " 'sources',\n",
              " 'sales',\n",
              " 'other',\n",
              " 'moderates',\n",
              " 'model',\n",
              " 'marketing',\n",
              " 'less',\n",
              " 'hypotheses',\n",
              " 'further',\n",
              " 'degree',\n",
              " 'competence',\n",
              " 'capabilities',\n",
              " '9',\n",
              " 'training',\n",
              " 'system',\n",
              " 'significantly',\n",
              " 'service',\n",
              " 'reverse',\n",
              " 'media',\n",
              " 'logistics',\n",
              " 'japanese',\n",
              " 'employees',\n",
              " 'development',\n",
              " 'demand',\n",
              " 'toward',\n",
              " 'this',\n",
              " 't',\n",
              " 'structure',\n",
              " 'stronger',\n",
              " 'strategic',\n",
              " 'smes',\n",
              " 'resources',\n",
              " 'reporting',\n",
              " 'predicts',\n",
              " 'perception',\n",
              " 'operational',\n",
              " 'one',\n",
              " 'issues',\n",
              " 'intensity',\n",
              " 'hypothesized',\n",
              " 'green',\n",
              " 'ethical',\n",
              " 'design',\n",
              " 'customers',\n",
              " 'board',\n",
              " 'rms',\n",
              " 'venture',\n",
              " 'through',\n",
              " 'size',\n",
              " 'sharing',\n",
              " 'shared',\n",
              " 'risk',\n",
              " 'reputations',\n",
              " 'products',\n",
              " 'process',\n",
              " 'labor',\n",
              " 'internal',\n",
              " 'innovative',\n",
              " 'increased',\n",
              " 'increase',\n",
              " 'from',\n",
              " 'favorable',\n",
              " 'environment',\n",
              " 'do',\n",
              " 'direct',\n",
              " 'cooperation',\n",
              " 'workforce',\n",
              " 'towards',\n",
              " 'top',\n",
              " 'timespecic',\n",
              " 'these',\n",
              " 'surprises',\n",
              " 'suggested',\n",
              " 'strongly',\n",
              " 'strategies',\n",
              " 'store',\n",
              " 'stated',\n",
              " 'stakeholder',\n",
              " 'skills',\n",
              " 'similarity',\n",
              " 'should',\n",
              " 'share',\n",
              " 'serving',\n",
              " 'selection',\n",
              " 'rms',\n",
              " 'research',\n",
              " 'possess',\n",
              " 'period',\n",
              " 'our',\n",
              " 'nfp',\n",
              " 'material',\n",
              " 'mastery',\n",
              " 'implementation',\n",
              " 'highinvolvement',\n",
              " 'hence',\n",
              " 'fp',\n",
              " 'external',\n",
              " 'exists',\n",
              " 'exchange',\n",
              " 'employees',\n",
              " 'earnings',\n",
              " 'each',\n",
              " 'diversity',\n",
              " 'data',\n",
              " 'association',\n",
              " 'advantage',\n",
              " 'adoption',\n",
              " 'worse',\n",
              " 'were',\n",
              " 'waste',\n",
              " 'wait',\n",
              " 'units',\n",
              " 'under',\n",
              " 'strong',\n",
              " 'stakeholders',\n",
              " 'regulation',\n",
              " 'quit',\n",
              " 'provide',\n",
              " 'profit',\n",
              " 'production',\n",
              " 'prior',\n",
              " 'pressure',\n",
              " 'predicted',\n",
              " 'per',\n",
              " 'participation',\n",
              " 'ownership',\n",
              " 'outcome',\n",
              " 'moderated',\n",
              " 'mismatches',\n",
              " 'mediate',\n",
              " 'matches',\n",
              " 'low',\n",
              " 'legislation',\n",
              " 'leadermember',\n",
              " 'involvementhr',\n",
              " 'intangible',\n",
              " 'inrole',\n",
              " 'industry',\n",
              " 'ideal',\n",
              " 'hypothesised',\n",
              " 'hospital',\n",
              " 'found',\n",
              " 'entrepreneurial',\n",
              " 'effects',\n",
              " 'effectiveness',\n",
              " 'ecodesign',\n",
              " 'dismissal',\n",
              " 'directly',\n",
              " 'diminish',\n",
              " 'current',\n",
              " 'cost',\n",
              " 'concern',\n",
              " 'competitiveness',\n",
              " 'celebrity',\n",
              " 'average',\n",
              " 'asset',\n",
              " 'among',\n",
              " 'all',\n",
              " 'affect',\n",
              " 'about',\n",
              " 'within',\n",
              " 'weak',\n",
              " 'voluntary',\n",
              " 'variable',\n",
              " 'trust',\n",
              " 'tqm',\n",
              " 'those',\n",
              " 'suppliers',\n",
              " 'supplier',\n",
              " 'staff',\n",
              " 'skill',\n",
              " 'signicant',\n",
              " 'significant',\n",
              " 'restaurants',\n",
              " 'relationships',\n",
              " 'relations',\n",
              " 'profitability',\n",
              " 'presence',\n",
              " 'planning',\n",
              " 'philanthropy',\n",
              " 'neo',\n",
              " 'moderate',\n",
              " 'mncs',\n",
              " 'members',\n",
              " 'local',\n",
              " 'layoffs',\n",
              " 'layoff',\n",
              " 'larger',\n",
              " 'labour',\n",
              " 'inuenced',\n",
              " 'into',\n",
              " 'interfirm',\n",
              " 'intentions',\n",
              " 'inducementhr',\n",
              " 'idealtype',\n",
              " 'hpws',\n",
              " 'generate',\n",
              " 'forces',\n",
              " 'food',\n",
              " 'following',\n",
              " 'emss',\n",
              " 'driving',\n",
              " 'does',\n",
              " 'dimensions',\n",
              " 'customers',\n",
              " 'climate',\n",
              " 'care',\n",
              " 'but',\n",
              " 'british',\n",
              " 'behaviors',\n",
              " 'behavior',\n",
              " 'based',\n",
              " 'appropriate',\n",
              " 'american',\n",
              " 'although',\n",
              " 'also',\n",
              " 'activities',\n",
              " '0',\n",
              " 'workplaces',\n",
              " 'whose',\n",
              " 'well',\n",
              " 'website',\n",
              " 'visibility',\n",
              " 'variables',\n",
              " 'value',\n",
              " 'uniqueness',\n",
              " 'two',\n",
              " 'turbulence',\n",
              " 'thus',\n",
              " 'three',\n",
              " 'technological',\n",
              " 'supported',\n",
              " 'supply',\n",
              " 'superior',\n",
              " 'suggests',\n",
              " 'suggest',\n",
              " 'successful',\n",
              " 'studies',\n",
              " 'strength',\n",
              " 'states',\n",
              " 'society',\n",
              " 'sc',\n",
              " 'roa',\n",
              " 'returns',\n",
              " 'result',\n",
              " 'regression',\n",
              " 'reduce',\n",
              " 'rather',\n",
              " 'rate',\n",
              " 'qualityenhancing',\n",
              " 'pursuing',\n",
              " 'protability',\n",
              " 'proposed',\n",
              " 'principal',\n",
              " 'practice',\n",
              " 'postsuccession',\n",
              " 'posits',\n",
              " 'philanthropic',\n",
              " 'performanceenhancing',\n",
              " 'patient',\n",
              " 'packagingrelated',\n",
              " 'overall',\n",
              " 'organizations',\n",
              " 'opportunity',\n",
              " 'operating',\n",
              " 'only',\n",
              " 'oce',\n",
              " 'number',\n",
              " 'most',\n",
              " 'might',\n",
              " 'measured',\n",
              " 'may',\n",
              " 'managers',\n",
              " 'manager',\n",
              " 'lowcost',\n",
              " 'link',\n",
              " 'likelihood',\n",
              " 'leads',\n",
              " 'la',\n",
              " 'knowledge',\n",
              " 'inversely',\n",
              " 'inventory',\n",
              " 'index',\n",
              " 'increases',\n",
              " 'identification',\n",
              " 'hypothesize',\n",
              " 'greek',\n",
              " 'government',\n",
              " 'general',\n",
              " 'female',\n",
              " 'expected',\n",
              " 'either',\n",
              " 'efficiency',\n",
              " 'ecoorganizational',\n",
              " 'disclosed',\n",
              " 'differentiation',\n",
              " 'developing',\n",
              " 'decreased',\n",
              " 'creativity',\n",
              " 'coverage',\n",
              " 'costefficiency',\n",
              " 'complementary',\n",
              " 'collective',\n",
              " 'coefcient',\n",
              " 'chinese',\n",
              " 'change',\n",
              " 'chain',\n",
              " 'certain',\n",
              " 'capability',\n",
              " 'can',\n",
              " 'appraisal',\n",
              " 'any',\n",
              " 'age',\n",
              " 'advertising',\n",
              " 't',\n",
              " 'years',\n",
              " 'worth',\n",
              " 'workplace',\n",
              " 'while',\n",
              " 'whereas',\n",
              " 'weaker',\n",
              " 'ventures',\n",
              " 'valuable',\n",
              " 'unmatched',\n",
              " 'unitlevel',\n",
              " 'total',\n",
              " 'timebased',\n",
              " 'tices',\n",
              " 'third',\n",
              " 'therefore',\n",
              " 'theory',\n",
              " 'testing',\n",
              " 'tested',\n",
              " 'test',\n",
              " 'tend',\n",
              " 'technologybased',\n",
              " 'technology',\n",
              " 'technical',\n",
              " 'task',\n",
              " 'synergies',\n",
              " 'summary',\n",
              " 'succession',\n",
              " 'substantive',\n",
              " 'subordinates',\n",
              " 'structural',\n",
              " 'speed',\n",
              " 'similar',\n",
              " 'signals',\n",
              " 'shows',\n",
              " 'settings',\n",
              " 'senior',\n",
              " 'selected',\n",
              " 'segment',\n",
              " 'see',\n",
              " 'sectors',\n",
              " 'sector',\n",
              " 'screen',\n",
              " 'return',\n",
              " 'retentionoriented',\n",
              " 'retailers',\n",
              " 'restaurant',\n",
              " 'requiring',\n",
              " 'reputational',\n",
              " 'reported',\n",
              " 'relative',\n",
              " 'relation',\n",
              " 'regulatory',\n",
              " 'reactions',\n",
              " 'radicalness',\n",
              " 'racial',\n",
              " 'prot',\n",
              " 'provided',\n",
              " 'profitsales',\n",
              " 'profits',\n",
              " 'productsservices',\n",
              " 'productservice',\n",
              " 'productrelated',\n",
              " 'private',\n",
              " 'predict',\n",
              " 'prachypothesis',\n",
              " 'position',\n",
              " 'policies',\n",
              " 'plants',\n",
              " 'pes',\n",
              " 'personality',\n",
              " 'persistence',\n",
              " 'perform',\n",
              " 'patents',\n",
              " 'past',\n",
              " 'partners',\n",
              " 'partners',\n",
              " 'particularly',\n",
              " 'p',\n",
              " 'outsourcing',\n",
              " 'organization',\n",
              " 'orders',\n",
              " 'order',\n",
              " 'operates',\n",
              " 'nonnegative',\n",
              " 'no',\n",
              " 'natural',\n",
              " 'my',\n",
              " 'multiple',\n",
              " 'motivation',\n",
              " 'moderator',\n",
              " 'moderating',\n",
              " 'mediates',\n",
              " 'mediated',\n",
              " 'measures',\n",
              " 'matched',\n",
              " 'listed',\n",
              " 'lending',\n",
              " 'learning',\n",
              " 'leaders',\n",
              " 'lead',\n",
              " 'language',\n",
              " 'inuences',\n",
              " 'investors',\n",
              " 'investor',\n",
              " 'investment',\n",
              " 'inverted',\n",
              " 'interact',\n",
              " 'institutions',\n",
              " 'institutional',\n",
              " 'instability',\n",
              " 'insignificant',\n",
              " 'initial',\n",
              " 'influenced',\n",
              " 'influence',\n",
              " 'individual',\n",
              " 'indirect',\n",
              " 'indicate',\n",
              " 'incentives',\n",
              " 'improves',\n",
              " 'improvement',\n",
              " 'improve',\n",
              " 'implement',\n",
              " 'i',\n",
              " 'hypothesises',\n",
              " 'hybrid',\n",
              " 'hospitals',\n",
              " 'highperformance',\n",
              " 'highly',\n",
              " 'heterogeneity',\n",
              " 'gscm',\n",
              " 'grafting',\n",
              " 'gps',\n",
              " 'generated',\n",
              " 'gender',\n",
              " 'future',\n",
              " 'furthermore',\n",
              " 'formal',\n",
              " 'follows',\n",
              " 'focus',\n",
              " 'findings',\n",
              " 'find',\n",
              " 'finally',\n",
              " 'figure',\n",
              " 'favorableness',\n",
              " 'factors',\n",
              " 'extensive',\n",
              " 'exploitation',\n",
              " 'expenditure',\n",
              " 'executive',\n",
              " 'engage',\n",
              " 'emphasizing',\n",
              " 'emphasize',\n",
              " 'emphasis',\n",
              " 'em',\n",
              " 'education',\n",
              " 'ecoprocess',\n",
              " 'economicenvironmental',\n",
              " 'dynamism',\n",
              " 'due',\n",
              " 'diversityequality',\n",
              " 'display',\n",
              " 'disclose',\n",
              " 'did',\n",
              " 'developmental',\n",
              " 'demographic',\n",
              " 'crew',\n",
              " 'country',\n",
              " 'costreduction',\n",
              " 'correlated',\n",
              " 'corporations',\n",
              " 'controlled',\n",
              " 'contingent',\n",
              " 'contender',\n",
              " 'consumeraimed',\n",
              " 'congenital',\n",
              " 'conflicting',\n",
              " 'conclusions',\n",
              " 'concerning',\n",
              " 'concentration',\n",
              " 'comprehensive',\n",
              " 'composition',\n",
              " 'compliance',\n",
              " 'complexity',\n",
              " 'complementarities',\n",
              " 'competencies',\n",
              " 'community',\n",
              " 'codes',\n",
              " 'climates',\n",
              " 'citizenship',\n",
              " 'ci',\n",
              " 'china',\n",
              " 'characterized',\n",
              " 'ceos',\n",
              " 'ceo',\n",
              " 'bundles',\n",
              " 'benets',\n",
              " 'availability',\n",
              " 'attitudes',\n",
              " 'after',\n",
              " 'affects',\n",
              " 'adopt',\n",
              " 'adjusted',\n",
              " 'additive',\n",
              " 'accumulation',\n",
              " 'accounting',\n",
              " 'above',\n",
              " '\\x05',\n",
              " 'rst',\n",
              " 'ndings',\n",
              " 'nding',\n",
              " '',\n",
              " 'yield',\n",
              " 'workfamily',\n",
              " 'workers',\n",
              " 'without',\n",
              " 'wiley',\n",
              " 'whether',\n",
              " 'websites',\n",
              " 'way',\n",
              " 'wages',\n",
              " 'volume',\n",
              " 'vision',\n",
              " 'view',\n",
              " 'varies',\n",
              " 'variance',\n",
              " 'values',\n",
              " 'utilized',\n",
              " 'using',\n",
              " 'ushaped',\n",
              " 'ushape',\n",
              " 'used',\n",
              " 'unrelated',\n",
              " 'unmeasured',\n",
              " 'universities',\n",
              " 'unit',\n",
              " 'uncertainty',\n",
              " 'types',\n",
              " 'type',\n",
              " 'turns',\n",
              " 'true',\n",
              " 'todays',\n",
              " 'threaten',\n",
              " 'theories',\n",
              " 'theoretical',\n",
              " 'tenure',\n",
              " 'technologies',\n",
              " 'teams',\n",
              " 'teambased',\n",
              " 'tax',\n",
              " 'tasks',\n",
              " 'table',\n",
              " 'supportive',\n",
              " 'supporting',\n",
              " 'suggesting',\n",
              " 'suffer',\n",
              " 'successors',\n",
              " 'substantially',\n",
              " 'subdimensions',\n",
              " 'study',\n",
              " 'stock',\n",
              " 'still',\n",
              " 'step',\n",
              " 'statistically',\n",
              " 'stating',\n",
              " 'stateowned',\n",
              " 'state',\n",
              " 'startup',\n",
              " 'spurious',\n",
              " 'specically',\n",
              " 'specic',\n",
              " 'specificity',\n",
              " 'sons',\n",
              " 'some',\n",
              " 'slack',\n",
              " 'since',\n",
              " 'simultaneously',\n",
              " 'simple',\n",
              " 'similarly',\n",
              " 'sign',\n",
              " 'side',\n",
              " 'shown',\n",
              " 'show',\n",
              " 'shorttermstay',\n",
              " 'services',\n",
              " 'servant',\n",
              " 'sensitivity',\n",
              " 'sense',\n",
              " 'senioritybased',\n",
              " 'seem',\n",
              " 'security',\n",
              " 'second',\n",
              " 'scrutiny',\n",
              " 'scheme',\n",
              " 'sample',\n",
              " 'salient',\n",
              " 'rm',\n",
              " 'rigorous',\n",
              " 'retail',\n",
              " 'respect',\n",
              " 'residual',\n",
              " 'represent',\n",
              " 'reports',\n",
              " 'report',\n",
              " 'repeated',\n",
              " 'reneries',\n",
              " 'rely',\n",
              " 'relevance',\n",
              " 'relational',\n",
              " 'relating',\n",
              " 'regulations',\n",
              " 'regions',\n",
              " 'reflect',\n",
              " 'reduction',\n",
              " 'reduces',\n",
              " 'receptive',\n",
              " 'receives',\n",
              " 'reason',\n",
              " 'rbv',\n",
              " 'radical',\n",
              " 'quits',\n",
              " 'question',\n",
              " 'pursued',\n",
              " 'purchasing',\n",
              " 'publics',\n",
              " 'providing',\n",
              " 'provides',\n",
              " 'prospectors',\n",
              " 'proposition',\n",
              " 'proposing',\n",
              " 'propose',\n",
              " 'proportionally',\n",
              " 'proportion',\n",
              " 'promote',\n",
              " 'project',\n",
              " 'progressive',\n",
              " 'programmes',\n",
              " 'productprocess',\n",
              " 'processing',\n",
              " 'processes',\n",
              " 'privately',\n",
              " 'previously',\n",
              " 'previous',\n",
              " 'prevents',\n",
              " 'prestart',\n",
              " 'press',\n",
              " 'predicting',\n",
              " 'potential',\n",
              " 'postulated',\n",
              " 'possibly',\n",
              " 'possibility',\n",
              " 'positions',\n",
              " 'posited',\n",
              " 'population',\n",
              " 'pool',\n",
              " 'political',\n",
              " 'point',\n",
              " 'plans',\n",
              " 'physical',\n",
              " 'pervasive',\n",
              " 'performancebased',\n",
              " 'people',\n",
              " 'path',\n",
              " 'party',\n",
              " 'partners',\n",
              " 'parties',\n",
              " 'particular',\n",
              " 'parameter',\n",
              " 'overarching',\n",
              " 'over',\n",
              " 'outsider',\n",
              " 'output',\n",
              " 'outletlevel',\n",
              " 'out',\n",
              " 'origin',\n",
              " 'organise',\n",
              " 'operators',\n",
              " 'onthejob',\n",
              " 'older',\n",
              " 'ofcials',\n",
              " 'note',\n",
              " 'notable',\n",
              " 'nonlisted',\n",
              " 'nonlinearly',\n",
              " 'nonfinancial',\n",
              " 'nonexecutive',\n",
              " 'national',\n",
              " 'name',\n",
              " 'must',\n",
              " 'munificence',\n",
              " 'much',\n",
              " 'moving',\n",
              " 'morale',\n",
              " 'months',\n",
              " 'monitoring',\n",
              " 'monitored',\n",
              " 'mixed',\n",
              " 'minimills',\n",
              " 'method',\n",
              " 'mentoring',\n",
              " 'mediator',\n",
              " 'means',\n",
              " 'markets',\n",
              " 'manufacturers',\n",
              " 'making',\n",
              " 'make',\n",
              " 'main',\n",
              " 'ltd',\n",
              " 'longterm',\n",
              " 'longitudinal',\n",
              " 'longer',\n",
              " 'logic',\n",
              " 'little',\n",
              " 'links',\n",
              " 'linearly',\n",
              " 'line',\n",
              " 'limited',\n",
              " 'like',\n",
              " 'lightpollution',\n",
              " 'leverage',\n",
              " 'leeway',\n",
              " 'led',\n",
              " 'learn',\n",
              " 'lb',\n",
              " 'l',\n",
              " 'knowledgeacquisition',\n",
              " 'katou',\n",
              " 'joint',\n",
              " 'john',\n",
              " 'issue',\n",
              " 'involve',\n",
              " 'involuntary',\n",
              " 'investments',\n",
              " 'inverse',\n",
              " 'international',\n",
              " 'interfunctional',\n",
              " 'interesting',\n",
              " 'interactions',\n",
              " 'intention',\n",
              " 'intensities',\n",
              " 'integrating',\n",
              " 'int',\n",
              " 'institutionally',\n",
              " 'insignicant',\n",
              " 'innovativepreventive',\n",
              " 'initiatives',\n",
              " 'initiative',\n",
              " 'ings',\n",
              " 'influencing',\n",
              " 'inferior',\n",
              " 'industrys',\n",
              " 'industrial',\n",
              " 'inducements',\n",
              " 'inducement',\n",
              " 'indicating',\n",
              " 'indicated',\n",
              " 'indexes',\n",
              " 'increasing',\n",
              " 'inclined',\n",
              " 'implied',\n",
              " 'impacts',\n",
              " 'immediately',\n",
              " 'imitability',\n",
              " 'ilm',\n",
              " 'illustrates',\n",
              " 'if',\n",
              " 'ie',\n",
              " 'hypotheis',\n",
              " 'hrbased',\n",
              " 'however',\n",
              " 'hold',\n",
              " 'highreputation',\n",
              " 'highpollution',\n",
              " 'highperforming',\n",
              " 'hierarchy',\n",
              " 'helping',\n",
              " 'headquartered',\n",
              " 'had',\n",
              " 'group',\n",
              " 'greatly',\n",
              " 'greatest',\n",
              " 'granger',\n",
              " 'goods',\n",
              " 'going',\n",
              " 'goal',\n",
              " 'globalization',\n",
              " 'global',\n",
              " 'giving',\n",
              " 'given',\n",
              " 'give',\n",
              " 'geographic',\n",
              " 'generally',\n",
              " 'functional',\n",
              " 'framework',\n",
              " 'foundations',\n",
              " 'formalization',\n",
              " 'force',\n",
              " 'focusing',\n",
              " 'first',\n",
              " 'firms',\n",
              " 'finding',\n",
              " 'feedback',\n",
              " 'fact',\n",
              " 'facilities',\n",
              " 'eect',\n",
              " 'eyes',\n",
              " 'extent',\n",
              " 'exposure',\n",
              " 'export',\n",
              " 'exploration',\n",
              " 'explain',\n",
              " 'experienced',\n",
              " 'expenditures',\n",
              " 'expectations',\n",
              " 'exhibits',\n",
              " 'exhibit',\n",
              " 'exerted',\n",
              " 'exchanges',\n",
              " 'except',\n",
              " 'examined',\n",
              " 'evidence',\n",
              " 'every',\n",
              " 'even',\n",
              " 'evaluated',\n",
              " 'estimate',\n",
              " 'equity',\n",
              " 'enterprise',\n",
              " 'enhanced',\n",
              " 'engaged',\n",
              " 'ems',\n",
              " 'empowerment',\n",
              " 'employing',\n",
              " 'employed',\n",
              " 'empirical',\n",
              " 'embodied',\n",
              " 'embark',\n",
              " 'electronic',\n",
              " 'elaborate',\n",
              " 'efcient',\n",
              " 'efciencybased',\n",
              " 'efciency',\n",
              " 'efficiencyperformance',\n",
              " 'efficacy',\n",
              " 'ecoproduct',\n",
              " 'economics',\n",
              " 'ecoefciency']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    }
  ]
}