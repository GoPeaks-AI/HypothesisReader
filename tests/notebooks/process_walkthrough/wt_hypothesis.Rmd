---
title: "Walkthrough - Hypothesis Extraction"
author: "Evan Canfield"
date: "12/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Import
## Libraries
```{r import_libraries}
  if (!require(pacman)) {install.packages('pacman')}
  p_load(
    dplyr
  )
```

## Assisting Functions
```{r}
#' Inspect Text String
inspect <- function(x, m = 100, span = 20) {
  n = m + span - 1
  x[m:n]
}
```

## Regex
```{r}
regex_hypo_marker <- "<split>hypo (.*?):"
```

## Data
```{r}
folder_path <- "./../../../inst/extdata/sample_documents/"
pdf_paths <- list.files(recursive = FALSE, 
                       path = folder_path, 
                       pattern = ".pdf", 
                       full.names = TRUE)
print(pdf_paths)
```
# Preceding Steps
## Process Text
```{r}
# Select Document Index
n = 16
input_path <- pdf_paths[n]
input_path
cat("\n\n")
input_text <- process_text(input_path)

inspect(input_text, m = 1, span = 10)
```

# Extract Hypothesis
## Define String Lookup Patterns
```{r}
split_tag <- "<split>"
hypothesis_tag <- "hypo (.*?):\\s*"
hypothesis_split_tag <- paste(split_tag, hypothesis_tag, sep = "")

```

## Split Lines with multiple hypothesis tags
```{r}
split_text <- stringr::str_split(
  string  = input_text,
  pattern = split_tag) %>%
  unlist()

# Select vector elements which contain hypothesis tags
logical_hypothesis_tag <- stringr::str_detect(
  string  = split_text,
  pattern = hypothesis_tag
)

hypothesis_001 <- split_text[logical_hypothesis_tag]
hypothesis_001
```

## Remove vector elements with token counts below minimum threshold
```{r}
# Drop Hypothesis lines with hypothesis tag only
hypothesis_002 <- drop_hypothesis_below_min_threshold(
  input_text = hypothesis_001
  )

hypothesis_002
```

## Filter vector elements based on hypothesis prediction model

```{r}
hypothesis_003 <- apply_fasttext_model(hypothesis_002)
hypothesis_003
```


```{r}
apply_model = TRUE
if (apply_model) {
  if (!(purrr::is_empty(hypothesis_002))) {
    
    hypothesis_003 <- apply_fasttext_model(hypothesis_002)
    
  } else {
    hypothesis_003 <- hypothesis_002
  }
}

hypothesis_003
```


## Apply fastText Model
### Walkthrough
#### Drop Hypothesis Tag
```{r}
model_input <- gen_fasttext_model_input(hypothesis_002)
model_input
```

### Create Predictions
```{r}
hypothesis_pred <- fastTextR::ft_predict(
  model   = ft_model,
  newdata = model_input,
  rval    = "dense"
) %>%
  as.data.frame() 

# Rename columns
col_names <- names(hypothesis_pred)

if ("__label__1" %in% col_names) {
  hypothesis_pred <- hypothesis_pred %>%
    dplyr::rename(yes = "__label__1")
}

if ("__label__0" %in% col_names) {
  hypothesis_pred <- hypothesis_pred %>%
    dplyr::rename(no = "__label__0")
}

hypothesis_pred
```

#### Generate Logical Vector 
```{r}
col_names <- names(hypothesis_pred)

## If no column not found, all elements are hypothesis
if (!("no" %in% col_names)) {
  response <- vector(
    mode   = "logical",
    length = length(model_input)
  )

  for (i in seq_along(model_input)) (response[i] <- TRUE)

  ## If yes column not found, all elements are not hypothesis
} else if (!("yes" %in% col_names)) {
  response <- vector(
    mode   = "logical",
    length = length(model_input))

  for (i in seq_along(model_input)) (response[i] <- FALSE)

} else {
  response <- hypothesis_pred %>%
    dplyr::mutate(
      Response = dplyr::if_else(
        condition = yes >= no,
        true      = TRUE,
        false     = FALSE
      )
    ) %>%
    dplyr::pull(Response)

}
```

#### Filter Hypothesis Statements with Logical Vector
```{r}
hypothesis_003 <- hypothesis_002[response]
hypothesis_003
```

## Extract Hypothesis number/label
```{r}
# Identify lines with hypothesis pattern
h_match <- hypothesis_003 %>%
  stringr::str_match(
    pattern = hypothesis_tag
  )

h_match_num <- h_match[,2]

h_match_num
```



## Identify unique hypothesis numbers
```{r}
# Identify unique hypothesis numbers
h_match_num_unq <- unique(h_match_num)

h_match_num_unq

# Remove known erroneous hypothesis formats (i.e.: NA)
error_hypothesis <- c("na")

h_match_num_unq <- setdiff(h_match_num_unq, error_hypothesis)

# Drop NA
h_match_num_unq <- h_match_num_unq[!is.na(h_match_num_unq)]

h_match_num_unq
```

#### Reduce to unique hypothesis
Drop 4 if 4a was already identified.
Drop 4a is 4 was already identified.
```{r}
  hypothesis_labels <- h_match_num_unq
  
  # hypothesis_labels <- c("1", "2a", "2b", "3a", "4", "2", "3", "3b", "1b")  
  # hypothesis_labels

  # Check if hypothesis label contains letters
  logical_hypothesis_labels_alpha <- grepl("[a-zA-Z]", hypothesis_labels)
  logical_hypothesis_labels_alpha
  
  # Extract Numbers
  regex_return_num <- "(\\d)+"

  hypothesis_numbers <- stringr::str_extract(
    string = hypothesis_labels,
    pattern = regex_return_num
  )
  
  hypothesis_numbers

  h_num_output <- c()
  h_label_output <- c()
  
  # hypothesis_labels_alpha <- hypothesis_labels_alpha[1:3]

  for (i in seq_along(logical_hypothesis_labels_alpha)) {
    
    h_label_alpha <- logical_hypothesis_labels_alpha[i]
    h_num <- hypothesis_numbers[i]
    h_label <- hypothesis_labels[i]
 
    # If label contains a letter
    if (h_label_alpha) {
      
      # Check if number already used in label
      if (!(h_num %in% h_label_output)) {
        
        h_label_output <- c(h_label_output, h_label)
        h_num_output <- c(h_num_output, h_num)
      
        }
      
    } else {
      
      if (!(h_num %in% h_num_output)) {
        
        h_label_output <- c(h_label_output, h_label)
        h_num_output <- c(h_num_output, h_num)
      
        }
    }
  }
  h_num_output
  h_label_output

  stringr::str_sort(x = h_label_output)
  
```

```{r}
h_match_num_unq <- unique_hypothesis_labels(h_match_num_unq)
h_match_num_unq
```

## Determine Vector Index of Initial Hypthesis Instance
```{r}
# Determine vector index of initial hypothesis statements
h_initial <- c()

for (i in h_match_num_unq){
  intial_idx <- tapply(seq_along(h_match_num),
                       h_match_num,
                       min)[i]
  h_initial <- c(h_initial, intial_idx)
}

h_initial

# Reduce text to only initial hypothesis instances
hypothesis_004 <- hypothesis_003[h_initial]
hypothesis_004
```

## Create Output Dataframe Columns
```{r}
regex_hypo_marker_2 <- "hypo (.*?):\\s*"

# Extract hypothesis labels
h_id <- hypothesis_004 %>%
  stringr::str_extract("hypo (.*?):") %>%
  stringr::str_remove_all("hypo ") %>%
  stringr::str_remove_all(":")

# Save current state for causality classification input
hypothesis_causality <- hypothesis_004

# Drop ~Hypo #:~ for entity extraction input
hypothesis_entity <- gsub(regex_hypo_marker_2,"", hypothesis_causality)
hypothesis_entity
```

## Create Output Dataframe
```{r}

# Create Dataframe with hypothesis number and hypothesis
df_hypothesis <- data.frame(
  h_id,
  hypothesis_entity,
  hypothesis_causality,
  stringsAsFactors = FALSE
)

df_hypothesis
```

## Modify Output Dataframe
```{r}
  # Rename and add Hypothesis Number
  df_hypothesis <- df_hypothesis %>%
    dplyr::rename(
      hypothesis = hypothesis_entity
    ) %>%
    dplyr::mutate(
      h_id = paste0("h_", h_id)
    ) %>%
    dplyr::select(h_id, hypothesis, hypothesis_causality)

  df_hypothesis
```

# Final Function
```{r}
hypothesis_extraction(input_text)
```

