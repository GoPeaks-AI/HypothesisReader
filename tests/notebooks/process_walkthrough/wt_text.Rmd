---
title: "Entity Extraction Performance Evaluation - R & Python"
author: "Evan Canfield"
date: "12/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose
The purpose of this notebook is to test how to implement the Entity Extraction model 

# Import
## Libraries
```{r import_libraries}
  if (!require(pacman)) {install.packages('pacman')}
  p_load(
    dplyr
  )
```

## Source Files
The following imports functions defined in the sourced R scripts.
```{r}
# # Import All Scripts
# script_path <- "../R/"
# file_paths <- list.files(recursive = TRUE,
#                          path = script_path, pattern = ".R",
#                          full.names = TRUE)
#
# for (file in file_paths){
#   source(file)
# }
```

## Data
```{r}
folder_path <- "./../../../inst/extdata/sample_documents/"
pdf_paths <- list.files(recursive = FALSE, 
                       path = folder_path, 
                       pattern = ".pdf", 
                       full.names = TRUE)
print(pdf_paths)
```

## Assisting Functions
```{r}
#' Inspect Text String
inspect <- function(x, m = 100, span = 20) {
  n = m + span - 1
  x[m:n]
  
}
```

## Regex
```{r}
## Identify Letters
regex_letters <- '[a-zA-Z]'

## Identify IP Address
regex_ip <- "(?:[\\d]{1,3})\\.(?:[\\d]{1,3})\\.(?:[\\d]{1,3})\\.(?:[\\d]{1,3})"

## Identify Parenthesis
regex_parens <- "\\(([^()]+)\\)"

## Identify Numbers
regex_return_num <- "(\\d)+"
```

# Process Data
```{r}
input_path <- pdf_paths[6]
input_path
input_text <- pdfminer$extract_text(input_path)
```

## Step 1
```{r}
processing_text <- input_text %>%
  stringr::str_split(pattern = "\r\n") %>% # Tabulizer
  stringr::str_split(pattern = "\n") %>% # Tika
  unlist()

processing_text[100:120]
```
## Remove from References/Bibliography
```{r}
## Remove Anything From References / Bibliography to End
## Define Sections
section_key <- c("References", "Bibliography",
                 "REFERENCES", "BIBIOGRAPHY")

### Convert to regex
regex_section <- gen_regex(
  input_string = section_key,
  match        = "exact"
)

### Return Logical Vector
logical_section <- stringr::str_detect(
  string  = processing_text,
  pattern = regex_section)

if (any(logical_section)){
  index <- min(which(logical_section == TRUE))
  processing_text <- processing_text[1:index-1]
}
```

## Normalize Case 
```{r}
# Normalize Case -------------------------------------------------------------
## Set everything to lowercase
processing_text <- tolower(processing_text)
```

## Remove Patterns
```{r}
# ## Remove Elements Which Match Removal Patterns
# processing_text <- processing_text[!processing_text %in% removal_patterns]
# 
# inspect()
```

## Drop Line W/ Only Numbers or Symbols
```{r}
## Drop lines with only numbers or symbols
processing_text <- remove_if_detect(
  input_vector   = processing_text,
  regex          = regex_letters,
  logical_method = "inverse"
)

```

## Drop Vectors With Length 1 or Less
```{r}
## Drop elements with length of 1 or less
logical_length <- nchar(processing_text) > 1
processing_text <- processing_text[logical_length]

# Drop any NA elements
processing_text <- processing_text[!is.na(processing_text)]
```

## Remove Months
```{r}
processing_text <- remove_if_detect(
  input_vector  = processing_text,
  remove_string = toupper(month.name),
  location      = "start"
)

## Drop Any NA Elements
processing_text <- processing_text[!is.na(processing_text)]
```

## Concatenate Hyphens
```{r}
## Concatenate Adjacent Elements If Initial Element Ends With Hyphen
processing_text <- concat_hypen_vector(processing_text)
```

## Downloaded Files
```{r}
## Remove elements which contain text related to downloading documents.

download_vec <- c('This content downloaded','http','jsto','DOI','doi')

processing_text <- remove_if_detect(
  input_vector  = processing_text,
  remove_string = download_vec,
  location      = "any"
)

```

## IP Addresses
```{r}
## Remove elements which contain IP addresses

processing_text <- remove_if_detect(
  input_vector = processing_text,
  regex        = regex_ip,
  location     = "any"
)

```

## Parenthesis
```{r}
# Parenthesis ----------------------------------------------------------------
## Remove text within parenthesis
### Define term to identify line splits
# line_split_indicator <- " -LINESPLIT-"
# 
# ### Concatenate all vector elements, separated by line split
# processing_text <- stringr::str_c(
#   processing_text,
#   collapse = line_split_indicator
# )
# 
# # Remove content within parenthesis
# processing_text <- stringr::str_remove_all(
#   string  = processing_text,
#   pattern = regex_parens
# )
# 
# # Split single string back into character vectors
# processing_text <- stringr::str_split(
#   string  = processing_text,
#   pattern = line_split_indicator) %>%
#   unlist()
```

## Empty Vectors
```{r}
# Empty Vectors --------------------------------------------------------------
## Drop empty vectors
processing_text <- processing_text[processing_text!=""]

## Drop NA elements
processing_text <- processing_text[!is.na(processing_text)]
```

## Symbols and Numbers
```{r}
# Numbers and Symbols (Second Time) ------------------------------------------
## Drop lines with only numbers or symbols
processing_text <- remove_if_detect(
  input_vector   = processing_text,
  regex          = regex_letters,
  logical_method = "inverse"
)

inspect(x = processing_text, m = 208, span = 5)
```
## Standardize Hypothesis / Proposition
```{r}
# Standardize Hypothesis/Propositions-----------------------------------------
## Hypothesis
processing_text <- standardize_hypothesis_proposition(
  input_string  = processing_text
)

# Remove trailing period for standardizes hypothesis tags
processing_text <- remove_period(
  input_string = processing_text
)

## Drop object names
processing_text <- unname(processing_text)

inspect(x = processing_text, m = 208, span = 5)
```
### Step-By-Step
#### Extract Phrase
```{r}
regex_hypo_condensed <- c(
  "(h|p|hypothesis|proposition)(\\s*)([0-9]{1,3}[a-zA-Z]|[0-9]{1,3})(\\:|\\.)?"
)

regex_standardize <- paste(
  "(h|p|hypothesis|proposition)(\\s*)",
  "([0-9]{1,3}[a-zA-Z]|[0-9]{1,3})(\\s*)(\\:|\\.)?", 
  sep = ""
)

input.v_test <- c(
  "h1b: managing foreign entrepreneurs negatively affect firm performance relative to hired local",
  "proposition 1: this is a proposition",
  "hypothesis 2a: this is a hypothesis",
  "proposition3: this is a proposition",
  "hypothesis4b: this is a hypothesis",
  "proposition5. this is a proposition",
  "hypothesis6b. this is a hypothesis",
  "proposition7 this is a proposition",
  "hypothesis8b this is a hypothesis",
  "h9b: this is a hypothesis",
  "p 5 this is a proposition",
  "p 6: this is a proposition",
  "hypothesis6b. this is a hypothesis",
  "hypothesis4b: this is a hypothesis",
  "proposition7 this is a proposition",
  "hypothesis8b this is a hypothesis",
  "hypothesis 4: this is a hypothesis",
  "no hypothesis or proposition"
)


extract_phrase <- stringr::str_extract(
    string  = input.v_test,
    pattern = regex_hypo_condensed
  )

extract_phrase
```


#### Drop Hypothesis ID if Alphanumeric Version Appeared Earlier
Drop 4 if 4a was already identified.

```{r}
# # extract_phrase_3
# 
# regex_return_num <- "(\\d)+"
# total_len <- length(extract_phrase_3)
# h_id_num.v <- stringr::str_extract(
#   string = extract_phrase_3, 
#   pattern = regex_return_num
#   )
# extract_phrase_4 <- extract_phrase_3
# 
# for (i in seq_along(extract_phrase_3)) {
#   
#   h_id_num <- h_id_num.v[i]
#   # print(h_id_num)
#   search.v <- extract_phrase_4[(i+1):total_len]
#   # print(search.v)
#   h_id_num_exact <- paste("\\b", h_id_num, "\\b", sep = "")
#   # print(h_id_num_exact)
#   detect <- stringr::str_detect(search.v, h_id_num_exact)
#   # print(detect)
#   detect_index <- which(detect == TRUE)
#   for (j in detect_index){
#     k <- i + j
#     # print(k)
#     extract_phrase_4[k] = NA
#   }
#   # print("")
#   
# }
```

## Remove period next to hypothesis marker
```{r}

input_string <- processing_text[210]

# Regex identifies hypothesis with trailing period
regex_hypo_marker_w_period <- "<split>hypo (.*?):\\s?."

# Extract identified value
extract_phrase <- stringr::str_extract(
  string  = input_string,
  pattern = regex_hypo_marker_w_period
)

# Remove trailing period
output_string <- stringr::str_replace(
  string      = input_string,
  pattern     = ":\\s?.",
  replacement = ":"
)
```


```{r}
processing_text <- remove_period(
  input_string = processing_text
)

## Drop object names
processing_text <- unname(processing_text)

inspect(x = processing_text, m = 208, span = 20)
```

## Tokenize Sentences
```{r}
# Tokenize Sentences ---------------------------------------------------------
## Convert Vector Elements into Sentences
processing_text <- stringr::str_c(
  processing_text,
  collapse = " "
)

processing_text <- tokenizers::tokenize_sentences(
  processing_text,
  strip_punct = FALSE) %>%
  unlist()

## Replace double spaces with single
processing_text <- stringr::str_replace_all(
  string      = processing_text,
  pattern     = "  ",
  replacement = " "
)

inspect(x = processing_text, m = 130, span = 10)

processing_text

```
## tokenize Sentence - Second Pass
```{r}
processing_text <- stringr::str_split(
  string  = processing_text, 
  pattern = "\\.") %>% 
  unlist()

## Drop empty vectors
processing_text <- processing_text[processing_text!=""]

inspect(x = processing_text, m = 150, span = 10)
```


## Downloading (Second Time)
```{r}
# Downloading (Second Time) --------------------------------------------------
  ## Remove elements which contain terms related to downloading files
  processing_text <- remove_if_detect(
    input_vector  = processing_text,
    remove_string = download_vec,
    location      = "any"
  )

inspect(x = processing_text, m = 150, span = 10)
```

## Symbols and Numbers (Second Time)
```{r}
  # Numbers and Symbols (Third Time) -------------------------------------------
  ## Drop lines with only numbers or symbols
  processing_text <- remove_if_detect(
    input_vector   = processing_text,
    regex          = regex_letters,
    logical_method = "inverse"
  )

inspect(x = processing_text, m = 90 , span = 10)
```

## Split Sentences with Multiple Hypothesis Tags
```{r}
processing_text <- break_out_hypothesis_tags(processing_text)

inspect(x = processing_text, m = 90 , span = 20)
```

## Misc Text Replacement
```{r}
  # Misc Text Replacement ------------------------------------------------------
  ## Replace double colons
  processing_text <- stringr::str_replace_all(
    string      = processing_text,
    pattern     = ": :",
    replacement = ":"
  )

  ## Remove extra white space
  processing_text <- stringr::str_squish(
    string = processing_text
  )

  ## Replace colon/period instances (: .)
  processing_text <- stringr::str_replace_all(
    string      = processing_text,
    pattern     = ": \\.",
    replacement = ":"
  )
  

inspect(x = processing_text, m = 150, span = 20)
```

# Component Function Testing
## Standardize Hypothesis
We need to adjust this function so that alpha numeric hypothesis numbers are grabbed.
### Inputs
```{r}
input_string_alphanum <- paste(
  "15, we would be unable to reject Hypothesis 1b"
)

input_string_no_hypo <- "This is a dummy"

input_string_num <- "This is Hypothesis 1 a purely numeric hypothesis"


## Generate regex identify hypotheses
regex_hypothesis_string <- gen_regex(
  input_string = regex_hypo,
  match        = "partial"
)
```

### Extract Hypothesis Phrases
```{r}
extract_phrase <- stringr::str_extract(
  string  = input_string_alphanum,
  pattern = regex_hypothesis_string
)

extract_phrase
```

### Extract Hypothesis Number
#### Existing
```{r}

extact_number <- stringr::str_extract(
  string  = extract_phrase,
  pattern = regex_return_num
)
extact_number
```

#### Update able to capture alpha numerics
```{r}
regex_return_alphanum <- '/\b(?![0-9]+\b)(?![a-z]+\b)[0-9a-z]+\b/i'

extact_number <- stringr::str_match(
  string  = extract_phrase,
  pattern = regex_return_alphanum
)
extact_number <- extract_phrase %>% stringr::str_split(pattern = " ")

extact_number <- extact_number[[1]][2]
```

```{r}
replacement_string <- paste0("<split>Hypo ", extact_number, ": ")
replacement_string
    # Replace hypothesis with new value
    output_string <- stringr::str_replace(
      string      = input_string_alphanum,
      pattern     = regex_hypothesis_string,
      replacement = replacement_string
    )
    
    output_string
```


```{r}
standardize_hypothesis <- Vectorize(
  function(input_string, regex_hypothesis_string){

    # Extract identified value
    extract_phrase <- stringr::str_extract(
      string  = input_string,
      pattern = regex_hypothesis_string
    )

    # Check if hypothesis detected
    if (!is.na(extract_phrase)){

      # Extract hypothesis number
      extact_number <- stringr::str_extract(
        string  = extract_phrase,
        pattern = regex_return_num
      )

      # Create new string
      replacement_string <- paste0("<split>Hypo ", extact_number, ": ")

      # Replace hypothesis with new value
      output_string <- stringr::str_replace(
        string      = input_string,
        pattern     = regex_hypothesis_string,
        replacement = replacement_string
      )

    } else {
      output_string <- input_string

    }

    output_string

  }
)
```

