---
title: "Entity Extraction Performance Evaluation - R & Python"
author: "Evan Canfield"
date: "12/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose
The purpose of this notebook is to test how to implement the Entity Extraction model 

# Import
## Libraries
```{r import_libraries}
  if (!require(pacman)) {install.packages('pacman')}
  p_load(
    dplyr,
    readxl,
    reticulate,
    rtika,
    stringr,
    tokenizers,
    tidyr
  )
```

## Source Files
The following imports functions defined in the sourced R scripts.
```{r}
# Import All Scripts
script_path <- "../R/"
file_paths <- list.files(recursive = TRUE, 
                         path = script_path, pattern = ".R", 
                         full.names = TRUE)

for (file in file_paths){
  source(file)
}
```

## Python Modules
```{r}
parser <- import("tika.parser")
```

## Data
```{r import_data}
# PDF Input
## Define Path
pdf_path <- "./../data/acadmic_papers_pdf_sample/jv04amj.pdf"

## Import and Convert to Text
pdf_tika_package <- parser$from_file(pdf_path)

pdf_txt_raw <- pdf_tika_package$content

# Patterns File
patterns_col <- c("remove","comments")
patterns_raw <- read_excel(path = "./../data/patterns.xlsx", 
                           col_names = patterns_col, )
removal_patterns <- patterns_raw %>% pull(remove)
```

## Regex
```{r}
## Identify Letters
regex_letters <- '[a-zA-Z]'

## Identify IP Address
regex_ip <- "(?:[\\d]{1,3})\\.(?:[\\d]{1,3})\\.(?:[\\d]{1,3})\\.(?:[\\d]{1,3})"

## Identify Parenthesis
regex_parens <- "\\(([^()]+)\\)"

## Identify Hypothesis Formats
regex_hypo <- c('h[0-9]{1,3}[a-zA-Z]\\:',
                'H[0-9]{1,3}[a-zA-Z]\\:',
                'h[0-9]{1,3}[a-zA-Z]\\.',
                'H[0-9]{1,3}[a-zA-Z]\\.',
                'h[0-9]{1,3}[a-zA-Z]',
                'H[0-9]{1,3}[a-zA-Z]',
                'hypothesis [0-9]{1,3}[a-zA-Z]\\:',
                'Hypothesis [0-9]{1,3}[a-zA-Z]\\:',
                'hypothesis [0-9]{1,3}[a-zA-Z]\\.',
                'Hypothesis [0-9]{1,3}[a-zA-Z]\\.',
                'hypothesis [0-9]{1,3}[a-zA-Z]',
                'Hypothesis [0-9]{1,3}[a-zA-Z]',
                'h[0-9]{1,3}\\:',
                'H[0-9]{1,3}\\:',
                'h[0-9]{1,3}\\.',
                'H[0-9]{1,3}\\.',
                'h[0-9]{1,3}',
                'H[0-9]{1,3}',
                'hypothesis [0-9]{1,3}\\:',
                'Hypothesis [0-9]{1,3}\\:',
                'hypothesis [0-9]{1,3}\\.',
                'Hypothesis [0-9]{1,3}\\.',
                'hypothesis [0-9]{1,3}',
                'Hypothesis [0-9]{1,3}')

## Identify Numbers
regex_return_num <- "(\\d)+"
```

# Set Inspect Processed Text Function
```{r}
inspect <- function(m = 100, i = 20){
  print(length(processing_text))
  n = m + i
  processing_text[m:n+i]
}
```

# Process Data
```{r}
input_text <- pdf_txt_raw
```

## Step 1
```{r}
  processing_text <- input_text %>%
    str_split(pattern = "\r\n") %>% # Tabulizer
    str_split(pattern = "\n") %>% # Tika
    unlist()

inspect(100)
```
## Step - Remove from References/Bibliography
```{r}
## Remove Anything From References / Bibliography to End
## Define Sections
section_key <- c("References", "Bibliography",
                 "REFERENCES", "BIBIOGRAPHY")

## Convert to Regex String
regex_section <- gen_regex(
  input_vector = section_key,
  match = "exact"
)

logical_section <- str_detect(processing_text, regex_section)

if (any(logical_section)){
  index <- min(which(logical_section == TRUE))
  processing_text <- processing_text[1:index-1]
}

inspect(100)
```

# Step - Remove Patterns
```{r}
## Remove Elements Which Match Removal Patterns
processing_text <- processing_text[!processing_text %in% removal_patterns]

inspect()
```

## Step - Drop Line W/ Only Numbers or Symbols
```{r}
## Drop Lines With Only Numbers or Symbols
processing_text <- remove_if_detect(
  input_vector = processing_text,
  regex_letters,
  logical_method = "inverse"
)

inspect()
```

## Step - Drop Vectors With Length 1 or Less
```{r}
## Drop Elements with Length of 1
## Return Logical Vector
logical_length <- nchar(processing_text) > 1

## Drop All Lines Length of 1 or Less
processing_text <- processing_text[logical_length]

## Drop Any NA Elements
processing_text <- processing_text[!is.na(processing_text)]

inspect()
```

## Step - Remove Months
```{r}
## Remove Elements which Start With Month
processing_text <- remove_if_detect(
  input_vector = processing_text,
  remove_vector = toupper(month.name),
  location = "start"
)

## Drop Any NA Elements
processing_text <- processing_text[!is.na(processing_text)]

inspect(230)
```

## Step - Concatenate Hyphens
```{r}
  ## Concatenate Adjacent Elements If Initial Element Ends With Hyphen

  processing_text <- concat_hypen_vector(processing_text)
```


















```{r}
# Process Text
text_processed <- process_text(input_text = pdf_txt_raw, 
                                  removal_patterns = patterns)

input_text <- text_processed

input_text
```

```{r}
  # Concatenate All Vector Elements, Separated By Line Split
  processing_text <- str_c(input_text, collapse = " ")
  processing_text <- tokenize_sentences(processing_text,
                                        strip_punct = FALSE) %>% unlist()

  # Replace Double Spaces
  processing_text <- str_replace_all(string = processing_text,
                            pattern = "  ",
                            replacement = " ")

  # Normalize Text ------------------------------------------------------------
  processing_text <- tolower(processing_text)
```

```{r}
# Regex - Between Hypo and Colon
regex_hypo_marker <- "<split>hypo (.*?):"

# Hypothesis Extraction -----------------------------------------------------
  # Identify Lines with Hypothesis Pattern
  h_match <- processing_text %>% str_match(regex_hypo_marker)
  
  # Extract Hypotheses Number
  h_match_num <- h_match[,2]
  
  # Identify Unique Hypothesis Numbers
  h_match_num_unq <- unique(h_match_num)
  
  # Drop NA
  h_match_num_unq <- h_match_num_unq[!is.na(h_match_num_unq)]
  
  # Determine Vector Index of Initial Hypothesis Statements
  h_initial <- c()
  for (i in h_match_num_unq){
    intial_idx <- tapply(seq_along(h_match_num),
                         h_match_num,
                         min)[i]
    h_initial <- c(h_initial, intial_idx)
  }
  
  # Reduce Text to Only Initial Hypothesis Instances
  h_statements <- processing_text[h_initial]
  
  h_statements
```

```{r}
  # Split Statements On Indicator (Defined in Processing) ---------------------
  ## Define
  split_indicator <- "<split>"

  ## Split on Indicator
  h_statements <- str_split(string = h_statements,
                                     pattern = split_indicator) %>%
    unlist()

  ## Detect Statements Which Contain "Hypo"
  logical_hypothesis_2 <- str_detect(h_statements, "hypo")

  ## Drop Statements that Do Not Include "Hypo"
  h_statements <- h_statements[logical_hypothesis_2]
  
  h_statements

```

```{r}
  # Drop ~Hypo #:~
  h_statements <- gsub(".*: ","",h_statements)
  
  h_statements
```


```{r}
  # Create Dataframe with Hypothesis Number and Hypothesis
  df_hypothesis <- as.data.frame(h_statements,
                                 stringsAsFactors = FALSE)
```


```{r}
df_hypothesis
```


```{r}
gsub(".*: ","",h_statements)
```


```{r}


  # Identify Hypothesis Statements --------------------------------------------
  ## Return Logical Vector
  logical_hypothesis_1 <- str_detect(processing_text, regex_hypothesis)

  ## Reduce Document to Only Hypothesis Statements
  hypothesis_statements <- processing_text[logical_hypothesis_1]

  # Split Statements On Indicator (Defined in Processing) ---------------------
  ## Define
  split_indicator <- "<split>"

  ## Split on Indicator
  hypothesis_statements <- str_split(string = hypothesis_statements,
                                     pattern = split_indicator) %>%
    unlist()

  ## Detect Statements Which Contain "Hypo"
  logical_hypothesis_2 <- str_detect(hypothesis_statements, "hypo")

  ## Drop Statements that Do Not Include "Hypo"
  hypothesis_statements <- hypothesis_statements[logical_hypothesis_2]

  # Create Dataframe with Hypothesis Number and Hypothesis
  df_hypothesis <- as.data.frame(hypothesis_statements,
                                 stringsAsFactors = FALSE)


  # Rename and add Hypothesis Number
  df_hypothesis <- df_hypothesis %>%
    rename(hypothesis = hypothesis_statements) %>%
    mutate(
      h_id = paste0("h_", row_number())
    ) %>%
    select(h_id, hypothesis)
```

